{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1760b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6aa2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "oofs = []\n",
    "\n",
    "weights = {'rf':2,'lr':1,'lgb':3}\n",
    "models = list(weights.keys())\n",
    "weights_list = list(weights.values())\n",
    "\n",
    "for model in models:\n",
    "    for index in range(5):\n",
    "        with open(f'predictions1/{model}_{index}.pkl','rb') as f:\n",
    "            predictions.append(pickle.load(f))\n",
    "    with open(f'oofs1/{model}.pkl','rb') as f:\n",
    "        oofs.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7764d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find best weights\n",
    "\n",
    "# weights_rf = [1,2,3,4,5]\n",
    "# weights_lr = [1,2,3,4,5]\n",
    "# weights_lgb = [1,2,3,4,5]\n",
    "\n",
    "# train_df = pd.read_csv('data/cleaned_train.csv',index_col=0)\n",
    "# y2 = train_df['class2'].map({'nonevent':0,'event':1})\n",
    "\n",
    "# current_best = 0\n",
    "              \n",
    "# for weight_rf in weights_rf:\n",
    "#     for weight_lr in weights_lr:\n",
    "#         for weight_lgb in weights_lgb:\n",
    "#             weights = {'rf':weight_rf,'lr':weight_lr,'lgb':weight_lgb}\n",
    "#             models = list(weights.keys())\n",
    "#             weights_list = list(weights.values())\n",
    "#             oof2 = []\n",
    "\n",
    "#             for index in range(len(y2)):\n",
    "#                 counter = [0,0]\n",
    "#                 preds = [oofs[i][index] for i in range(len(oofs))]\n",
    "#                 for i,pred in enumerate(preds):\n",
    "#                     counter[0] += weights_list[i] * pred[0]\n",
    "#                     counter[1] += weights_list[i] * pred[1]\n",
    "\n",
    "#                 oof2.append(np.argmax(counter))\n",
    "\n",
    "#             acc2 = accuracy_score(y2,oof2)\n",
    "#             if acc2 > current_best:\n",
    "#                 current_best = acc2\n",
    "#                 best_rf = weight_rf\n",
    "#                 best_lr = weight_lr\n",
    "#                 best_lgb = weight_lgb\n",
    "\n",
    "# best_rf,best_lr,best_lgb,current_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fcb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perplexity optimizer\n",
    "# train_df = pd.read_csv('data/cleaned_train.csv',index_col=\"date\")\n",
    "# y2 = train_df['class2'].map({'nonevent':0,'event':1})\n",
    "\n",
    "# def get_perplexity(coefficient=1):\n",
    "#     confidences = []\n",
    "\n",
    "#     for index in range(len(y2)):\n",
    "#         counter = [0,0]\n",
    "#         preds = [oofs[i][index] for i in range(len(oofs))]\n",
    "#         for i,pred in enumerate(preds):\n",
    "#             counter[0] += weights_list[i] * pred[0]\n",
    "#             counter[1] += weights_list[i] * pred[1]\n",
    "#         confidences.append(coefficient * counter[1] / (counter[0] + coefficient * counter[1]))\n",
    "\n",
    "#     return np.exp(log_loss(y2,confidences)/len(y2))\n",
    "\n",
    "# current_best = float('inf')\n",
    "\n",
    "# for i in range(15,35):\n",
    "#     if get_perplexity(coefficient=i/20) < current_best:\n",
    "#         best_coefficient = i / 20\n",
    "#         current_best = get_perplexity(coefficient=i/20)\n",
    "\n",
    "# best_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00af5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f0d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 class\n",
      "ACC: 0.9017467248908297\n",
      "PERP: 1.3155682121178425\n",
      "[[216  13]\n",
      " [ 32 197]]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation score, used as estimate of final accuracy\n",
    "train_df = pd.read_csv('data/cleaned_train.csv',index_col=0)\n",
    "y2 = train_df['class2'].map({'nonevent':0,'event':1})\n",
    "oof2 = []\n",
    "confidences = []\n",
    "\n",
    "for index in range(len(y2)):\n",
    "    counter = [0,0]\n",
    "    preds = [oofs[i][index] for i in range(len(oofs))]\n",
    "    for i,pred in enumerate(preds):\n",
    "        counter[0] += weights_list[i] * pred[0]\n",
    "        counter[1] += weights_list[i] * pred[1]\n",
    "\n",
    "    oof2.append(np.argmax(counter))\n",
    "    confidences.append(coefficient * counter[1] / (counter[0] + coefficient * counter[1]))\n",
    "    \n",
    "acc2 = accuracy_score(y2,oof2)\n",
    "print(\"2 class\")\n",
    "print(\"ACC:\",str(acc2))\n",
    "# perplexity\n",
    "print(\"PERP:\",np.exp(log_loss(y2,confidences)))\n",
    "print(confusion_matrix(y2,oof2))\n",
    "with open('results/acc2.pkl','wb') as f:\n",
    "    pickle.dump(acc2,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac51c200",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_confidences = []\n",
    "stage1_predictions = []\n",
    "length = len(predictions[0])\n",
    "\n",
    "for index in range(length):\n",
    "    counter = [0,0]\n",
    "    preds = [predictions[i][index] for i in range(len(predictions))]\n",
    "    for i,pred in enumerate(preds):\n",
    "        weight_index = int(i / 5) \n",
    "        counter[0] += weights_list[weight_index] * pred[0]\n",
    "        counter[1] += weights_list[weight_index] * pred[1]\n",
    "    stage1_predictions.append(np.argmax(counter))\n",
    "    confidence = coefficient * counter[1] / (counter[0] + coefficient * counter[1])\n",
    "    final_confidences.append(confidence)\n",
    "        \n",
    "len(stage1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868e83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_indexes = []\n",
    "\n",
    "for index, prediction in enumerate(stage1_predictions):\n",
    "    if prediction == 1:\n",
    "        stage2_indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e508687",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/stage1_predictions.pkl','wb') as f:\n",
    "    pickle.dump(stage1_predictions,f)\n",
    "    \n",
    "with open('results/final_confidences.pkl','wb') as f:\n",
    "    pickle.dump(final_confidences,f)\n",
    "    \n",
    "with open('data/stage2_indexes.pkl','wb') as f:\n",
    "    pickle.dump(stage2_indexes,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda19a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
